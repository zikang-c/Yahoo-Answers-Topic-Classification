{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "import string\n",
    "from nltk.stem.snowball import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from string import punctuation, ascii_lowercase, digits\n",
    "\n",
    "\n",
    "import re\n",
    "from functools import lru_cache\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import fasttext\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import itertools\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Conv1D, SpatialDropout1D, Bidirectional\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "with open('split_data_v2.pkl', 'rb') as f:\n",
    "    X_train, X_val, y_train, y_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all_list = (X_train['question'] + \" \" + X_train['best_answer']).tolist()\n",
    "X_val_all_list = (X_val['question'] + \" \" + X_val['best_answer']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_all = X_train.copy()\n",
    "# X_val_all = X_val.copy()\n",
    "\n",
    "# X_train_all['question_answer'] = X_train_all['question'] + \" \" + X_train_all['best_answer']\n",
    "# X_val_all['question_answer'] = X_val_all['question'] + \" \" + X_val_all['best_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save train and validation into txt format\n",
    "# X_train_all.to_csv(\"FastText_all_emd_no_url.train\",columns=[\"question_answer\"],index=False,header=False)\n",
    "# X_val_all.to_csv(\"FastText_all_emd_no_url.val\",columns=[\"question_answer\"],index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_all = X_train_all[['question_answer']]\n",
    "# X_val_all = X_val_all[['question_answer']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 53M words\n",
      "Number of words:  182856\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   93063 lr:  0.000000 avg.loss:  0.689027 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# ft_model = fasttext.train_unsupervised(\"FastText_all_emd_no_url.train\", model=\"skipgram\", dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_model.save_model(\"ft_model_dim100.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = fasttext.load_model(\"ft_model_dim100.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.get_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasttext_embeddings_batch(texts, ft_model, max_length=100):\n",
    "    embedding_dim = ft_model.get_dimension()  # FastText embedding dimension\n",
    "    batch_embeddings = np.zeros((len(texts), max_length, embedding_dim), dtype=np.float32)\n",
    "\n",
    "    for i, text in enumerate(texts):\n",
    "        words = text.split()[:max_length]  # Truncate to max_length\n",
    "        word_embeddings = [ft_model.get_word_vector(word) for word in words]\n",
    "        batch_embeddings[i, :len(word_embeddings)] = word_embeddings  # Fill in the embeddings\n",
    "\n",
    "    return batch_embeddings\n",
    "\n",
    "\n",
    "def process_in_batches(texts, ft_model, batch_size=1000, max_length=100):\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_embeddings = get_fasttext_embeddings_batch(batch_texts, ft_model, max_length=max_length)\n",
    "        all_embeddings.append(batch_embeddings)\n",
    "\n",
    "    return np.vstack(all_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Embeddings Shape: (1085280, 100, 100)\n",
      "Validation Embeddings Shape: (271320, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_length = 100  # Define the maximum sequence length\n",
    "batch_size = 100  # Define the batch size\n",
    "\n",
    "# Process training and validation embeddings in batches\n",
    "X_train_emb = process_in_batches(X_train_all_list, ft_model, batch_size=batch_size, max_length=max_length)\n",
    "X_val_emb = process_in_batches(X_val_all_list, ft_model, batch_size=batch_size, max_length=max_length)\n",
    "\n",
    "print(f\"Training Embeddings Shape: {X_train_emb.shape}\")\n",
    "print(f\"Validation Embeddings Shape: {X_val_emb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('X_train_emb.npy', X_train_emb)\n",
    "# np.save('X_val_emb.npy', X_val_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and validation embeddings\n",
    "X_train_emb = np.load('X_train_emb.npy')\n",
    "X_val_emb = np.load('X_val_emb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Embeddings Shape: (1085280, 100, 100)\n",
      "Validation Embeddings Shape: (271320, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Embeddings Shape: {X_train_emb.shape}\")\n",
    "print(f\"Validation Embeddings Shape: {X_val_emb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_all_list = X_train_all['question_answer'].tolist()\n",
    "# X_val_all_list = X_val_all['question_answer'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare training and validation embeddings\n",
    "# max_length = 100  # Define the maximum sequence length\n",
    "# X_train_emb = get_fasttext_embeddings(X_train_all_list, ft_model, max_length=max_length)\n",
    "# X_val_emb = get_fasttext_embeddings(X_val_all_list, ft_model, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Model\n",
    "max_length = 100\n",
    "sequence_input = Input(shape=(max_length, ft_model.get_dimension()), dtype='float32')\n",
    "\n",
    "# Add layers with the advanced techniques\n",
    "x = SpatialDropout1D(0.2)(sequence_input)\n",
    "x = Conv1D(64, 5, activation='relu')(x)  # Convolution for local patterns\n",
    "x = Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2))(x)  # Bidirectional LSTM\n",
    "x = Dense(512, activation='relu')(x)  # Fully connected layer\n",
    "x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "x = Dense(512, activation='relu')(x)  # Another dense layer\n",
    "outputs = Dense(len(set(y_train)), activation='softmax')(x)  # Output for multiclass classification\n",
    "\n",
    "model = Model(sequence_input, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Model\n",
    "LR = 1e-3  # Learning rate\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor (you can use 'val_accuracy' or others)\n",
    "    patience=2,          # Number of epochs with no improvement to wait\n",
    "    restore_best_weights=True,  # Restore model weights from the epoch with the best value of the monitored metric\n",
    "    verbose=1            # Display logs when training stops\n",
    ")\n",
    "\n",
    "# Define ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    factor=0.1,          # Reduce learning rate by this factor\n",
    "    patience=3,          # Number of epochs with no improvement before reducing learning rate\n",
    "    min_lr=0.00001,      # Minimum learning rate\n",
    "    verbose=1            # Display logs when learning rate is reduced\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m33914/33915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6651 - loss: 1.0576"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Train the model with callbacks\n",
    "history = model.fit(\n",
    "    X_train_emb, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=10,  # Set a high number, as training will stop early if no improvement\n",
    "    validation_data=(X_val_emb, y_val),\n",
    "    callbacks=[early_stopping, reduce_lr]  # Add both callbacks here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Training History\n",
    "s, (at, al) = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "# Accuracy plot\n",
    "at.plot(history.history['accuracy'], c='b')\n",
    "at.plot(history.history['val_accuracy'], c='r')\n",
    "at.set_title('Model Accuracy')\n",
    "at.set_ylabel('Accuracy')\n",
    "at.set_xlabel('Epoch')\n",
    "at.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Loss plot\n",
    "al.plot(history.history['loss'], c='m')\n",
    "al.plot(history.history['val_loss'], c='c')\n",
    "al.set_title('Model Loss')\n",
    "al.set_ylabel('Loss')\n",
    "al.set_xlabel('Epoch')\n",
    "al.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Memory: 16.00 GB\n",
      "Available Memory: 8.90 GB\n",
      "Memory Used by Process: 2.19 GB\n",
      "Large variables (size > 10 MB):\n",
      "X_train: 448.35 MB\n",
      "X_val: 111.99 MB\n",
      "y_train: 16.56 MB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import psutil\n",
    "import os\n",
    "import gc\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"\n",
    "    Check current memory usage and available memory of the Python process.\n",
    "    \"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    total_mem = psutil.virtual_memory().total / (1024 ** 3)  # Total memory in GB\n",
    "    available_mem = psutil.virtual_memory().available / (1024 ** 3)  # Available memory in GB\n",
    "    used_mem = process.memory_info().rss / (1024 ** 3)  # Memory used by this Python process in GB\n",
    "\n",
    "    print(f\"Total Memory: {total_mem:.2f} GB\")\n",
    "    print(f\"Available Memory: {available_mem:.2f} GB\")\n",
    "    print(f\"Memory Used by Process: {used_mem:.2f} GB\")\n",
    "\n",
    "def list_large_variables(threshold=10):\n",
    "    \"\"\"\n",
    "    List variables in the global scope that exceed a memory threshold.\n",
    "    Args:\n",
    "        threshold (int): Memory size threshold in MB to list variables.\n",
    "    \"\"\"\n",
    "    large_vars = []\n",
    "    for var_name, var_value in globals().items():\n",
    "        try:\n",
    "            size = sys.getsizeof(var_value) / (1024 ** 2)  # Convert size to MB\n",
    "            if size > threshold:\n",
    "                large_vars.append((var_name, size))\n",
    "        except Exception as e:\n",
    "            pass  # Skip objects that can't be sized\n",
    "\n",
    "    if large_vars:\n",
    "        print(\"Large variables (size > {} MB):\".format(threshold))\n",
    "        for name, size in sorted(large_vars, key=lambda x: -x[1]):\n",
    "            print(f\"{name}: {size:.2f} MB\")\n",
    "    else:\n",
    "        print(\"No large variables found exceeding the threshold.\")\n",
    "\n",
    "# Example usage\n",
    "get_memory_usage()  # Check current memory usage and available memory\n",
    "list_large_variables(threshold=10)  # List variables larger than 10 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
